{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from magpie import grasp as gt\n",
    "import rtde_control\n",
    "import rtde_receive\n",
    "from magpie.motor_code import Motors\n",
    "from magpie import ur5 as ur5\n",
    "import time\n",
    "import numpy as np\n",
    "import copy\n",
    "import magpie\n",
    "from magpie.gripper import Gripper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "[Open3D INFO] Resetting default logger to print to terminal.\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "from PIL import Image\n",
    "import open3d as o3d\n",
    "import matplotlib.pyplot as plt\n",
    "from magpie.perception import pcd\n",
    "from open3d.web_visualizer import draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from magpie import realsense_wrapper as real\n",
    "rsc = real.RealSense()\n",
    "rsc.initConnection()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-12 13:25:32.943847: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-12 13:25:32.943883: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-12 13:25:32.944765: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-12 13:25:32.950001: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-12 13:25:33.731112: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from magpie.perception.label_owlvit import LabelOWLViT\n",
    "path = \"google/owlvit-base-patch32\"\n",
    "label_vit = LabelOWLViT(pth=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'magpie.gripper' from '/home/will/MAGPIE/magpie/gripper.py'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(gt)\n",
    "importlib.reload(ur5)\n",
    "importlib.reload(magpie.gripper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seg(index):\n",
    "    p, rgbd_image = rsc.getPCD()\n",
    "    image = np.array(rgbd_image.color)\n",
    "    queries = [\"a photo of a yellow rubber duck\"]\n",
    "    # queries = [\"a photo of a tail\"]\n",
    "    # queries = [\"a photo of a black handle of a pair of scissors\"]\n",
    "    abbrevq = [\"duck\"]\n",
    "    label_vit.set_threshold(0.005)\n",
    "    # bboxes, uboxes = label_vit.label(image, queries, abbrevq, topk=True, plot=True)\n",
    "    bboxes, uboxes = label_vit.label(image, queries, abbrevq, topk=True, plot=False)\n",
    "    rgbd_image, cpcd, tmat, pcaFrame = pcd.get_segment(\n",
    "                                            label_vit.sorted_labeled_boxes_coords, \n",
    "                                            # label_vit.boxes, \n",
    "                                            index, \n",
    "                                            rgbd_image, \n",
    "                                            rsc, \n",
    "                                            type=\"box-dbscan\", \n",
    "                                            #  type=\"box\", \n",
    "                                            #  method=\"quat\", \n",
    "                                            method=\"iterative\", \n",
    "                                            #  display=False,\n",
    "                                            display=False,\n",
    "                                            viz_scale=1000)\n",
    "    tmat, tmat[:3, 3]\n",
    "    \n",
    "    return cpcd, tmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load arrays in saved_poses/ folder as array of arrays\n",
    "saved_poses = []\n",
    "for i in range(5):\n",
    "    saved_poses.append(np.load(f'saved_poses/pose_{i+1}.npy', allow_pickle=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(saved_poses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmats = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeeded to open the port\n",
      "Succeeded to change the baudrate\n",
      "[TxRxResult] There is no status packet!\n",
      "Moving speed of dxl ID: 1 set to 100 \n",
      "Moving speed of dxl ID: 2 set to 100 \n",
      "Position of dxl ID: 1 set to 303 \n",
      "Position of dxl ID: 2 set to 729 \n"
     ]
    }
   ],
   "source": [
    "ur = ur5.UR5_Interface()\n",
    "try:\n",
    "    ur.start()\n",
    "    currentPose = ur.getPose()\n",
    "    ur.open_gripper()\n",
    "    ur.stop()\n",
    "\n",
    "except Exception as e:\n",
    "    ur.stop()\n",
    "    raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ur = ur5.UR5_Interface()\n",
    "try:\n",
    "    ur.start()\n",
    "    currentPose = ur.getPose()\n",
    "    ur.close_gripper()\n",
    "    ur.stop()\n",
    "\n",
    "except Exception as e:\n",
    "    ur.stop()\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ur = ur5.UR5_Interface()\n",
    "sleepRate = 3\n",
    "\n",
    "try:\n",
    "    ur.start()\n",
    "    currentPose = ur.getPose()\n",
    "    ur.moveL(saved_poses[1])\n",
    "    time.sleep(sleepRate)\n",
    "    ur.open_gripper()\n",
    "    cpcd, tmat = seg(index=0)\n",
    "    \n",
    "    tmat_gripper = np.array([[1, 0, 0, 0],\n",
    "                                 [0, 1, 0, 0],\n",
    "                                 [0, 0, 1, 0.08],\n",
    "                                 [0, 0, 0, 1]])\n",
    "\n",
    "    ee_to_base = ur.get_tcp_pose()\n",
    "\n",
    "    full_transform = ee_to_base \n",
    "\n",
    "    o3d.visualization.draw_geometries([cpcd])\n",
    "    \n",
    "    print(full_transform)\n",
    "    #ur.moveL(full_transform)\n",
    "\n",
    "    time.sleep(sleepRate)\n",
    "\n",
    "\n",
    "\n",
    "    ur.stop()\n",
    "\n",
    "except Exception as e:\n",
    "    ur.stop()\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ur = ur5.UR5_Interface()\n",
    "sleepRate = 3\n",
    "\n",
    "try:\n",
    "    ur.start()\n",
    "    currentPose = ur.get_tcp_pose()\n",
    "    print(currentPose)\n",
    "except Exception as e:\n",
    "    ur.stop()\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ur = ur5.UR5_Interface()\n",
    "try:\n",
    "    ur.start()\n",
    "    np.save('saved_poses_2/pose_down.npy', ur.get_tcp_pose())\n",
    "except Exception as e:\n",
    "    ur.stop()\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ur = ur5.UR5_Interface()\n",
    "sleepRate = 3\n",
    "\n",
    "try:\n",
    "    ur.start()\n",
    "    currentPose = ur.getPose()\n",
    "    p = np.load(f'saved_poses_2/pose_down.npy', allow_pickle=True)\n",
    "    ur.moveL(p)\n",
    "    time.sleep(sleepRate)\n",
    "\n",
    "\n",
    "    ur.stop()\n",
    "\n",
    "except Exception as e:\n",
    "    ur.stop()\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeeded to open the port\n",
      "Succeeded to change the baudrate\n",
      "Moving speed of dxl ID: 1 set to 100 \n",
      "Moving speed of dxl ID: 2 set to 100 \n",
      "  \u001b[38;5;1m 0.1695  \u001b[0m \u001b[38;5;1m-0.9852  \u001b[0m \u001b[38;5;1m 0.02507 \u001b[0m \u001b[38;5;4m-0.3854  \u001b[0m  \u001b[0m\n",
      "  \u001b[38;5;1m-0.9119  \u001b[0m \u001b[38;5;1m-0.1471  \u001b[0m \u001b[38;5;1m 0.3832  \u001b[0m \u001b[38;5;4m-0.1741  \u001b[0m  \u001b[0m\n",
      "  \u001b[38;5;1m-0.3739  \u001b[0m \u001b[38;5;1m-0.08782 \u001b[0m \u001b[38;5;1m-0.9233  \u001b[0m \u001b[38;5;4m 0.1651  \u001b[0m  \u001b[0m\n",
      "  \u001b[38;5;244m 0       \u001b[0m \u001b[38;5;244m 0       \u001b[0m \u001b[38;5;244m 0       \u001b[0m \u001b[38;5;244m 1       \u001b[0m  \u001b[0m\n",
      "\n",
      "z-axis dot product: [0.997]\n",
      "modified indices: [0 2 2]\n",
      "modified indices: [0 1 2]\n",
      "z-axis dot product: [0.832]\n",
      "modified indices: [1 2 0]\n",
      "z-axis dot product: [0.06]\n",
      "modified indices: [0 0 2]\n",
      "modified indices: [0 1 2]\n",
      "z-axis dot product: [0.86]\n",
      "modified indices: [1 2 0]\n",
      "z-axis dot product: [-0.277]\n",
      "flipping z axis\n",
      "flipping x-axis\n"
     ]
    }
   ],
   "source": [
    "name = \"pose_5\"\n",
    "sleepRate = 3\n",
    "\n",
    "ur = ur5.UR5_Interface()\n",
    "try:\n",
    "    ur.start()\n",
    "    currentPose = ur.getPose()\n",
    "    print(currentPose)\n",
    "\n",
    "    merged_pcd = o3d.geometry.PointCloud()\n",
    "    \n",
    "    for k, target_pose in enumerate(saved_poses):\n",
    "        ur.moveL(target_pose)\n",
    "        time.sleep(sleepRate)\n",
    "\n",
    "        # Capture point cloud and transformation matrix\n",
    "        cpcd, tmat = seg(index=1 if k == 4 else 0)\n",
    "\n",
    "        rotation_matrix = np.array([[0, 1, 0, 0],\n",
    "                            [-1, 0, 0, 0],\n",
    "                            [0, 0, 1, 0],\n",
    "                            [0, 0, 0, 1]])\n",
    "\n",
    "        #tmat = tmat @ rotation_matrix\n",
    "\n",
    "        o3d.io.write_point_cloud(f\"saved_pcd/cpcd{k+1}.ply\", cpcd)\n",
    "\n",
    "        # Transformation matrix for gripper length\n",
    "        tmat_gripper = np.array([[1, 0, 0, 0],\n",
    "                                 [0, 1, 0, 0],\n",
    "                                 [0, 0, 1, 0.08],\n",
    "                                 [0, 0, 0, 1]])\n",
    "\n",
    "        # Get the transformation matrix of the end effector in the base frame\n",
    "        ee_to_base = ur.get_tcp_pose()\n",
    "\n",
    "        \n",
    "        cpcd.transform(rotation_matrix)  # End effector to base frame\n",
    "        cpcd.transform(ee_to_base)  # End effector to base frame\n",
    "\n",
    "        # Save the transformed point cloud\n",
    "        o3d.io.write_point_cloud(f\"saved_pcd/cpcd{k+1}_t.ply\", cpcd)\n",
    "\n",
    "        # Use ICP to align the new point cloud with the merged point cloud\n",
    "        if k == 0:\n",
    "            merged_pcd = cpcd\n",
    "        else:\n",
    "            threshold = 0.055  # Distance threshold for ICP\n",
    "            init_transform = np.eye(4)  # Initial guess for the transformation\n",
    "            reg_p2p = o3d.pipelines.registration.registration_icp(\n",
    "                cpcd, merged_pcd, threshold, init_transform,\n",
    "                o3d.pipelines.registration.TransformationEstimationPointToPoint(),\n",
    "                o3d.pipelines.registration.ICPConvergenceCriteria(max_iteration=1800))\n",
    "            \n",
    "            # Transform the new point cloud using the result of ICP\n",
    "            cpcd.transform(reg_p2p.transformation)\n",
    "            \n",
    "            # Merge the point clouds\n",
    "            merged_pcd += cpcd\n",
    "\n",
    "    ur.stop()\n",
    "except Exception as e:\n",
    "    ur.stop()\n",
    "    raise e\n",
    "\n",
    "# Save the merged point cloud\n",
    "o3d.io.write_point_cloud(f\"saved_pcd/merged_pcd.ply\", merged_pcd)\n",
    "\n",
    "# Visualize the merged point cloud\n",
    "o3d.visualization.draw_geometries([merged_pcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ur.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capture point cloud and transformation matrix\n",
    "cpcd, tmat = seg(index=0)\n",
    "o3d.io.write_point_cloud(f\"saved_pcd/cpcd{1}.ply\", cpcd)\n",
    "\n",
    "# Transformation matrix for gripper length\n",
    "tmat_gripper = np.array([[1, 0, 0, 0],\n",
    "                            [0, 1, 0, 0],\n",
    "                            [0, 0, 1, 0],\n",
    "                            [0, 0, 0, 1]])\n",
    "\n",
    "# Get the transformation matrix of the end effector in the base frame\n",
    "ee_to_base = ur.get_tcp_pose()\n",
    "\n",
    "\n",
    "cpcd.transform(ee_to_base)  # End effector to base frame\n",
    "\n",
    "# Save the transformed point cloud\n",
    "o3d.io.write_point_cloud(f\"saved_pcd/cpcd{1}_t.ply\", cpcd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = o3d.io.read_point_cloud(f\"saved_pcd/cpcd1_t.ply\")\n",
    "o3d.visualization.draw_geometries([merged])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set matrix\n",
    "# tmat = np.array([[ 0.91574736, -0.35602909,  0.18614527, -0.02848649],\n",
    "#        [-0.40073104, -0.77640133,  0.48643151,  0.14332736],\n",
    "#        [ 0.02866033,  0.52004256,  0.85365937,  0.33750796],\n",
    "#        [ 0.        ,  0.        ,  0.        ,  1.        ]])\n",
    "\n",
    "tmat = np.array([[ 0.98665647, -0.16180182, -0.01814324,  0.04438557],\n",
    "       [-0.1565328 , -0.97333117,  0.16770185,  0.04194964],\n",
    "       [ 0.04479385,  0.1626241 ,  0.98567079,  0.32025074],\n",
    "       [ 0.        ,  0.        ,  0.        ,  1.        ]])\n",
    "\n",
    "aperture = 37\n",
    "# z_offset = G.aperture_to_z(aperture)/1000.0\n",
    "\n",
    "mmc = copy.deepcopy(tmat[:3, 3])\n",
    "# grasp_pose = [mmc[1], -mmc[0], mmc[2]]\n",
    "grasp_pose = mmc\n",
    "tmat[:3, 3] = [0, 0, 0]\n",
    "homePose = None\n",
    "z_offset = 100/1000.0\n",
    "z_offset -= 0.035\n",
    "z_offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move gripper to cartesian pos\n",
    "# OR orient gripper in place\n",
    "name = \"pose_5\"\n",
    "sleepRate = 4\n",
    "# time.sleep(sleepRate)\n",
    "ur = ur5.UR5_Interface()\n",
    "try:\n",
    "    ur.start()\n",
    "    currentPose = ur.getPose()\n",
    "    print(currentPose)\n",
    "\n",
    "    ur.moveL(saved_poses[4])\n",
    "    time.sleep(sleepRate)\n",
    "    time.sleep(sleepRate)\n",
    "    ur.stop()\n",
    "except Exception as e:\n",
    "    ur.stop()\n",
    "    raise(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 1\n",
    "# this does the [x, y, z] --> [y, -x, z] grasp pose switch, and the -y inversio on the y-axis orientation\n",
    "# rgbd_image, cpcd, tmat = pcd|.get_segment(label_vit.boxes, index, rgbd_image, rsc, type=\"box\", display=False)\n",
    "rgbd_image, cpcd, tmat, pcaFrame = pcd.get_segment(\n",
    "                                        label_vit.sorted_labeled_boxes_coords, \n",
    "                                        # label_vit.boxes, \n",
    "                                         index, \n",
    "                                         rgbd_image, \n",
    "                                         rsc, \n",
    "                                         type=\"box-dbscan\", \n",
    "                                        #  type=\"box\", \n",
    "                                        #  method=\"quat\", \n",
    "                                         method=\"iterative\", \n",
    "                                        #  display=False,\n",
    "                                         display=True,\n",
    "                                         viz_scale=1000)\n",
    "tmat, tmat[:3, 3]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move gripper to cartesian pos\n",
    "# OR orient gripper in place\n",
    "sleepRate = 1.5\n",
    "# time.sleep(sleepRate)\n",
    "ur = ur5.UR5_Interface()\n",
    "try:\n",
    "    ur.start()\n",
    "    # homePose = ur.get_tcp_pose()\n",
    "    homePose = ur.getPose()\n",
    "    currentPose = ur.getPose()\n",
    "    desiredPose = np.matmul(np.array(currentPose), tmat)\n",
    "    print(\"Desired Pose: \", desiredPose)\n",
    "    # in-place (or best attempt) re-orientation\n",
    "    # ur.moveL(desiredPose)\n",
    "    ## move to cartesian pos\n",
    "    gt.move_to_L(grasp_pose, ur, z_offset=z_offset)    \n",
    "    print(\"Done moving to block\")\n",
    "    time.sleep(sleepRate)\n",
    "    time.sleep(sleepRate)\n",
    "    ur.stop()\n",
    "except Exception as e:\n",
    "    ur.stop()\n",
    "    raise(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move home\n",
    "ur = ur5.UR5_Interface()\n",
    "try:\n",
    "    ur.start()\n",
    "    # time.sleep(sleepRate)\n",
    "    # homePose = np.array([[-0.024, -0.998, -0.062, -0.261],\n",
    "    #                     [-0.999,  0.021,  0.035, -0.162],\n",
    "    #                     [-0.033,  0.063, -0.997,  0.221],\n",
    "    #                     [ 0.   ,  0.   ,  0.   ,  1.   ]])\n",
    "    ur.moveL(homePose)\n",
    "    # gt_home = ur.getPose()\n",
    "    # print(np.array(gt_home))\n",
    "    time.sleep(sleepRate * 3)\n",
    "    ur.stop()\n",
    "except Exception as e:\n",
    "    ur.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT EXECUTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # orient and move gripper to cartesian pos\n",
    "# sleepRate = 1.5\n",
    "# ur = ur5.UR5_Interface()\n",
    "# try:\n",
    "#     servoPort = \"/dev/ttyACM0\"\n",
    "#     ur.start()\n",
    "#     time.sleep(sleepRate)\n",
    "#     homePose = ur.get_tcp_pose()    \n",
    "#     '''\n",
    "#     stopping point 2/15:\n",
    "#     this works so far\n",
    "#     take home pos\n",
    "#     add translation on the gripper frame to the goal x, y\n",
    "#     apply tmat to the goal\n",
    "#     move to goal (translates on x, y and orients at the same time)\n",
    "#     ## does this address the fact that orientation is not achievable in standstill?\n",
    "\n",
    "#     then: take orig Z (from original gripper frame): [0, 0, dZ]\n",
    "#     transform by tmat (the current orientation of the gripper)\n",
    "#     add transformed dZ to the goal position\n",
    "#     move\n",
    "#     works!\n",
    "#     '''\n",
    "#     dX,dY,dZ = gt.get_world_frame(grasp_pose, ur, z_offset=z_offset)\n",
    "\n",
    "#     goal1 = copy.deepcopy(homePose)\n",
    "#     goal1 = np.array(goal1)\n",
    "#     # goal1[:3, 3] += [dX, dY, 0]\n",
    "#     goal1[:3, 3] += [dX, dY, dZ]\n",
    "#     goal1 = np.array(goal1) @ tmat\n",
    "#     ur.moveL(goal1)\n",
    "#     time.sleep(sleepRate)\n",
    "\n",
    "#     # todo: take currentPose and validate orientation?\n",
    "#     goal2 = goal1\n",
    "#     posd = [0, 0, dZ] @ tmat[:3, :3]\n",
    "#     goal2 = np.array(goal2)\n",
    "#     goal2[:3, 3] += posd\n",
    "#     # ur.moveL(goal2)\n",
    "#     time.sleep(sleepRate)\n",
    "#     '''\n",
    "#     end of working section\n",
    "#     '''\n",
    "#     ur.stop()\n",
    "# except Exception as e:\n",
    "#     ur.stop()\n",
    "#     raise(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
