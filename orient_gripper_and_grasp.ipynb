{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from magpie import grasp as gt\n",
    "import rtde_control\n",
    "import rtde_receive\n",
    "from magpie.motor_code import Motors\n",
    "from magpie import ur5 as ur5\n",
    "import time\n",
    "import numpy as np\n",
    "import copy\n",
    "import magpie\n",
    "from magpie.gripper import Gripper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "from PIL import Image\n",
    "import open3d as o3d\n",
    "import matplotlib.pyplot as plt\n",
    "from magpie.perception import pcd\n",
    "from open3d.web_visualizer import draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from magpie import realsense_wrapper as real\n",
    "rsc = real.RealSense()\n",
    "rsc.initConnection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-02 17:44:02.363079: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-02 17:44:02.363108: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-02 17:44:02.364127: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-02 17:44:02.369257: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-02 17:44:03.122471: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from magpie.perception.label_owlvit import LabelOWLViT\n",
    "path = \"google/owlvit-base-patch32\"\n",
    "label_vit = LabelOWLViT(pth=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'magpie.gripper' from '/home/will/MAGPIE/magpie/gripper.py'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(gt)\n",
    "importlib.reload(ur5)\n",
    "importlib.reload(magpie.gripper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seg(index):\n",
    "    p, rgbd_image = rsc.getPCD()\n",
    "    image = np.array(rgbd_image.color)\n",
    "    queries = [\"a photo of an apple\", \"a photo of a lemon\", \"a photo of a lime\", \"a photo of a pear\", \"a photo of a onion\"]\n",
    "    queries = [\"a photo of an blue cylindrical container\", \"a photo of a small red cubic block\", \"a photo of a screwdriver handle\" ]\n",
    "    queries = [\"a photo of a black student ID card\", \"a photo of a small orange fruit\", \"a photo of a small plastic bag\"]\n",
    "    queries = [\"a photo of an avocado\", \"a photo of a small orange fruit\", \"a photo of a small plastic bag\", \"a photo of a paper airplane\"]\n",
    "    queries = [\"a photo of a water bottle with a red top\"]\n",
    "    queries = [\"a photo of a blue block\"]\n",
    "    # queries = [\"a photo of a tail\"]\n",
    "    # queries = [\"a photo of a black handle of a pair of scissors\"]\n",
    "    abbrevq = [\"apple\", \"lemon\", \"lime\", \"pear\", \"onion\"]\n",
    "    abbrevq = [\"blue\", \"block\", \"handle\"]\n",
    "    abbrevq = [\"card\", \"orange\", \"bag\"]\n",
    "    abbrevq = [\"avocado\", \"orange\", \"bag\", \"paper airplane\"]\n",
    "    abbrevq = [\"block\"]\n",
    "    label_vit.set_threshold(0.005)\n",
    "    # bboxes, uboxes = label_vit.label(image, queries, abbrevq, topk=True, plot=True)\n",
    "    bboxes, uboxes = label_vit.label(image, queries, abbrevq, topk=True, plot=False)\n",
    "    rgbd_image, cpcd, tmat, pcaFrame = pcd.get_segment(\n",
    "                                            label_vit.sorted_labeled_boxes_coords, \n",
    "                                            # label_vit.boxes, \n",
    "                                            index, \n",
    "                                            rgbd_image, \n",
    "                                            rsc, \n",
    "                                            type=\"box-dbscan\", \n",
    "                                            #  type=\"box\", \n",
    "                                            #  method=\"quat\", \n",
    "                                            method=\"iterative\", \n",
    "                                            #  display=False,\n",
    "                                            display=False,\n",
    "                                            viz_scale=1000)\n",
    "    tmat, tmat[:3, 3]\n",
    "    \n",
    "    return cpcd, tmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load arrays in saved_poses/ folder as array of arrays\n",
    "saved_poses = []\n",
    "for i in range(3):\n",
    "    saved_poses.append(np.load(f'saved_poses/pose_{i+1}.npy', allow_pickle=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmats = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeeded to open the port\n",
      "Succeeded to change the baudrate\n",
      "Moving speed of dxl ID: 1 set to 100 \n",
      "Moving speed of dxl ID: 2 set to 100 \n",
      "  \u001b[38;5;1m 0.1695  \u001b[0m \u001b[38;5;1m-0.9852  \u001b[0m \u001b[38;5;1m 0.02506 \u001b[0m \u001b[38;5;4m-0.3854  \u001b[0m  \u001b[0m\n",
      "  \u001b[38;5;1m-0.9119  \u001b[0m \u001b[38;5;1m-0.1471  \u001b[0m \u001b[38;5;1m 0.3832  \u001b[0m \u001b[38;5;4m-0.1741  \u001b[0m  \u001b[0m\n",
      "  \u001b[38;5;1m-0.3739  \u001b[0m \u001b[38;5;1m-0.0878  \u001b[0m \u001b[38;5;1m-0.9233  \u001b[0m \u001b[38;5;4m 0.1651  \u001b[0m  \u001b[0m\n",
      "  \u001b[38;5;244m 0       \u001b[0m \u001b[38;5;244m 0       \u001b[0m \u001b[38;5;244m 0       \u001b[0m \u001b[38;5;244m 1       \u001b[0m  \u001b[0m\n",
      "\n",
      "modified indices: [2 1 2]\n",
      "modified indices: [0 1 2]\n",
      "z-axis dot product: [0.849]\n",
      "[[-0.051 -0.857 -0.514 -0.204]\n",
      " [-0.998  0.02   0.066 -0.086]\n",
      " [-0.047  0.516 -0.855  0.29 ]\n",
      " [ 0.     0.     0.     1.   ]] 0\n",
      "z-axis dot product: [0.907]\n",
      "[[-0.038 -0.95  -0.311 -0.309]\n",
      " [-0.998  0.018  0.067 -0.087]\n",
      " [-0.058  0.313 -0.948  0.229]\n",
      " [ 0.     0.     0.     1.   ]] 1\n",
      "modified indices: [2 2 1]\n",
      "modified indices: [2 0 1]\n",
      "z-axis dot product: [0.833]\n",
      "[[-0.034 -0.967 -0.251 -0.362]\n",
      " [-0.998  0.017  0.067 -0.087]\n",
      " [-0.061  0.252 -0.966  0.193]\n",
      " [ 0.     0.     0.     1.   ]] 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RTDEControlInterface: Could not receive data from robot...\n",
      "RTDEControlInterface Exception: Operation canceled\n",
      "RTDEControlInterface: Robot is disconnected, reconnecting...\n",
      "RTDEControlInterface Exception: Timeout connecting to UR dashboard server.\n",
      "RTDEReceiveInterface Exception: Operation canceled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconnecting...\n"
     ]
    }
   ],
   "source": [
    "name = \"pose_5\"\n",
    "sleepRate = 3\n",
    "\n",
    "ur = ur5.UR5_Interface()\n",
    "try:\n",
    "    ur.start()\n",
    "    currentPose = ur.getPose()\n",
    "    print(currentPose)\n",
    "\n",
    "    merged_pcd = o3d.geometry.PointCloud()\n",
    "    \n",
    "    for k, target_pose in enumerate(saved_poses):\n",
    "        ur.moveL(target_pose)\n",
    "        time.sleep(sleepRate)\n",
    "\n",
    "        # Capture point cloud and transformation matrix\n",
    "        cpcd, tmat = seg(index=1 if k == 4 else 0)\n",
    "        o3d.io.write_point_cloud(f\"saved_pcd/cpcd{k+1}.ply\", cpcd)\n",
    "\n",
    "        # Transformation matrix for gripper length\n",
    "        tmat_gripper = np.array([[1, 0, 0, 0],\n",
    "                                 [0, 1, 0, 0],\n",
    "                                 [0, 0, 1, 0],\n",
    "                                 [0, 0, 0, 1]])\n",
    "\n",
    "        # Get the transformation matrix of the end effector in the base frame\n",
    "        ee_to_base = ur.get_tcp_pose()\n",
    "\n",
    "        # Apply transformations\n",
    "        if k==0:\n",
    "            cpcd.transform(tmat_gripper)  # Adjust for gripper length\n",
    "        print(ee_to_base, k)\n",
    "        cpcd.transform(ee_to_base)  # End effector to base frame\n",
    "\n",
    "        # Save the transformed point cloud\n",
    "        o3d.io.write_point_cloud(f\"saved_pcd/cpcd{k+1}_t.ply\", cpcd)\n",
    "\n",
    "        # Use ICP to align the new point cloud with the merged point cloud\n",
    "        if k == 0:\n",
    "            merged_pcd = cpcd\n",
    "        else:\n",
    "            threshold = 0.02  # Distance threshold for ICP\n",
    "            init_transform = np.eye(4)  # Initial guess for the transformation\n",
    "            reg_p2p = o3d.pipelines.registration.registration_icp(\n",
    "                cpcd, merged_pcd, threshold, init_transform,\n",
    "                o3d.pipelines.registration.TransformationEstimationPointToPoint())\n",
    "            \n",
    "            # Transform the new point cloud using the result of ICP\n",
    "            cpcd.transform(reg_p2p.transformation)\n",
    "            \n",
    "            # Merge the point clouds\n",
    "            merged_pcd += cpcd\n",
    "\n",
    "    ur.stop()\n",
    "except Exception as e:\n",
    "    ur.stop()\n",
    "    raise e\n",
    "\n",
    "# Save the merged point cloud\n",
    "o3d.io.write_point_cloud(f\"saved_pcd/merged_pcd.ply\", merged_pcd)\n",
    "\n",
    "# Visualize the merged point cloud\n",
    "o3d.visualization.draw_geometries([merged_pcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged= o3d.geometry.PointCloud()\n",
    "for i in range(5):\n",
    "    cpcd = o3d.io.read_point_cloud(f\"saved_pcd/cpcd{i+1}_t.ply\")\n",
    "    merged += cpcd\n",
    "\n",
    "o3d.visualization.draw_geometries([merged])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([merged_pcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.065"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set matrix\n",
    "# tmat = np.array([[ 0.91574736, -0.35602909,  0.18614527, -0.02848649],\n",
    "#        [-0.40073104, -0.77640133,  0.48643151,  0.14332736],\n",
    "#        [ 0.02866033,  0.52004256,  0.85365937,  0.33750796],\n",
    "#        [ 0.        ,  0.        ,  0.        ,  1.        ]])\n",
    "\n",
    "tmat = np.array([[-0.93571753, -0.30185443, -0.18252837, -0.01585103],\n",
    "        [ 0.14381697, -0.79893656,  0.58396665, -0.06580893],\n",
    "        [-0.32210151,  0.52017715,  0.79099074,  0.25853016],\n",
    "        [ 0.        ,  0.        ,  0.        ,  1.        ]])\n",
    "\n",
    "aperture = 37\n",
    "# z_offset = G.aperture_to_z(aperture)/1000.0\n",
    "\n",
    "mmc = copy.deepcopy(tmat[:3, 3])\n",
    "# grasp_pose = [mmc[1], -mmc[0], mmc[2]]\n",
    "grasp_pose = mmc\n",
    "tmat[:3, 3] = [0, 0, 0]\n",
    "homePose = None\n",
    "z_offset = 100/1000.0\n",
    "z_offset -= 0.035\n",
    "z_offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dashboard client deadline expired\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'servoStop'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 7\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 7\u001b[0m     \u001b[43mur\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# homePose = ur.get_tcp_pose()\u001b[39;00m\n",
      "File \u001b[0;32m~/MAGPIE/magpie/ur5.py:92\u001b[0m, in \u001b[0;36mUR5_Interface.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\" Connect to RTDE and the gripper \"\"\"\u001b[39;00m\n\u001b[0;32m---> 92\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mctrl \u001b[38;5;241m=\u001b[39m \u001b[43mrtde_control\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRTDEControlInterface\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrobotIP\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecv \u001b[38;5;241m=\u001b[39m rtde_receive\u001b[38;5;241m.\u001b[39mRTDEReceiveInterface( \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrobotIP, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfreq )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Timeout connecting to UR dashboard server.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m     ur\u001b[38;5;241m.\u001b[39mstop()\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m---> 22\u001b[0m     \u001b[43mur\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m(e)\n",
      "File \u001b[0;32m~/MAGPIE/magpie/ur5.py:104\u001b[0m, in \u001b[0;36mUR5_Interface.stop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstop\u001b[39m( \u001b[38;5;28mself\u001b[39m ):\n\u001b[1;32m    103\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" Shutdown robot and gripper connections \"\"\"\u001b[39;00m\n\u001b[0;32m--> 104\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mctrl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mservoStop\u001b[49m()\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mctrl\u001b[38;5;241m.\u001b[39mstopScript()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'servoStop'"
     ]
    }
   ],
   "source": [
    "# move gripper to cartesian pos\n",
    "# OR orient gripper in place\n",
    "sleepRate = 1.5\n",
    "# time.sleep(sleepRate)\n",
    "ur = ur5.UR5_Interface()\n",
    "try:\n",
    "    ur.start()\n",
    "    # homePose = ur.get_tcp_pose()\n",
    "    homePose = ur.getPose()\n",
    "    currentPose = ur.getPose()\n",
    "    desiredPose = np.matmul(np.array(currentPose), tmat)\n",
    "    print(\"Desired Pose: \", desiredPose)\n",
    "    # in-place (or best attempt) re-orientation\n",
    "    # ur.moveL(desiredPose)\n",
    "    ## move to cartesian pos\n",
    "    gt.move_to_L(grasp_pose, ur, z_offset=z_offset)    \n",
    "    print(\"Done moving to block\")\n",
    "    time.sleep(sleepRate)\n",
    "    time.sleep(sleepRate)\n",
    "    ur.stop()\n",
    "except Exception as e:\n",
    "    ur.stop()\n",
    "    raise(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move home\n",
    "ur = ur5.UR5_Interface()\n",
    "try:\n",
    "    ur.start()\n",
    "    # time.sleep(sleepRate)\n",
    "    # homePose = np.array([[-0.024, -0.998, -0.062, -0.261],\n",
    "    #                     [-0.999,  0.021,  0.035, -0.162],\n",
    "    #                     [-0.033,  0.063, -0.997,  0.221],\n",
    "    #                     [ 0.   ,  0.   ,  0.   ,  1.   ]])\n",
    "    ur.moveL(homePose)\n",
    "    # gt_home = ur.getPose()\n",
    "    # print(np.array(gt_home))\n",
    "    time.sleep(sleepRate * 3)\n",
    "    ur.stop()\n",
    "except Exception as e:\n",
    "    ur.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move gripper to cartesian pos\n",
    "# OR orient gripper in place\n",
    "name = \"pose_5\"\n",
    "sleepRate = 4\n",
    "# time.sleep(sleepRate)\n",
    "ur = ur5.UR5_Interface()\n",
    "try:\n",
    "    ur.start()\n",
    "    currentPose = ur.getPose()\n",
    "    print(currentPose)\n",
    "\n",
    "    ur.moveL(saved_poses[4])\n",
    "    time.sleep(sleepRate)\n",
    "    time.sleep(sleepRate)\n",
    "    ur.stop()\n",
    "except Exception as e:\n",
    "    ur.stop()\n",
    "    raise(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 1\n",
    "# this does the [x, y, z] --> [y, -x, z] grasp pose switch, and the -y inversio on the y-axis orientation\n",
    "# rgbd_image, cpcd, tmat = pcd|.get_segment(label_vit.boxes, index, rgbd_image, rsc, type=\"box\", display=False)\n",
    "rgbd_image, cpcd, tmat, pcaFrame = pcd.get_segment(\n",
    "                                        label_vit.sorted_labeled_boxes_coords, \n",
    "                                        # label_vit.boxes, \n",
    "                                         index, \n",
    "                                         rgbd_image, \n",
    "                                         rsc, \n",
    "                                         type=\"box-dbscan\", \n",
    "                                        #  type=\"box\", \n",
    "                                        #  method=\"quat\", \n",
    "                                         method=\"iterative\", \n",
    "                                        #  display=False,\n",
    "                                         display=True,\n",
    "                                         viz_scale=1000)\n",
    "tmat, tmat[:3, 3]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT EXECUTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # orient and move gripper to cartesian pos\n",
    "# sleepRate = 1.5\n",
    "# ur = ur5.UR5_Interface()\n",
    "# try:\n",
    "#     servoPort = \"/dev/ttyACM0\"\n",
    "#     ur.start()\n",
    "#     time.sleep(sleepRate)\n",
    "#     homePose = ur.get_tcp_pose()    \n",
    "#     '''\n",
    "#     stopping point 2/15:\n",
    "#     this works so far\n",
    "#     take home pos\n",
    "#     add translation on the gripper frame to the goal x, y\n",
    "#     apply tmat to the goal\n",
    "#     move to goal (translates on x, y and orients at the same time)\n",
    "#     ## does this address the fact that orientation is not achievable in standstill?\n",
    "\n",
    "#     then: take orig Z (from original gripper frame): [0, 0, dZ]\n",
    "#     transform by tmat (the current orientation of the gripper)\n",
    "#     add transformed dZ to the goal position\n",
    "#     move\n",
    "#     works!\n",
    "#     '''\n",
    "#     dX,dY,dZ = gt.get_world_frame(grasp_pose, ur, z_offset=z_offset)\n",
    "\n",
    "#     goal1 = copy.deepcopy(homePose)\n",
    "#     goal1 = np.array(goal1)\n",
    "#     # goal1[:3, 3] += [dX, dY, 0]\n",
    "#     goal1[:3, 3] += [dX, dY, dZ]\n",
    "#     goal1 = np.array(goal1) @ tmat\n",
    "#     ur.moveL(goal1)\n",
    "#     time.sleep(sleepRate)\n",
    "\n",
    "#     # todo: take currentPose and validate orientation?\n",
    "#     goal2 = goal1\n",
    "#     posd = [0, 0, dZ] @ tmat[:3, :3]\n",
    "#     goal2 = np.array(goal2)\n",
    "#     goal2[:3, 3] += posd\n",
    "#     # ur.moveL(goal2)\n",
    "#     time.sleep(sleepRate)\n",
    "#     '''\n",
    "#     end of working section\n",
    "#     '''\n",
    "#     ur.stop()\n",
    "# except Exception as e:\n",
    "#     ur.stop()\n",
    "#     raise(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
