{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from magpie import grasp as gt\n",
    "import rtde_control\n",
    "import rtde_receive\n",
    "from magpie.motor_code import Motors\n",
    "from magpie import ur5 as ur5\n",
    "import time\n",
    "import numpy as np\n",
    "import copy\n",
    "import magpie\n",
    "from magpie.gripper import Gripper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "[Open3D INFO] Resetting default logger to print to terminal.\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "from PIL import Image\n",
    "import open3d as o3d\n",
    "import matplotlib.pyplot as plt\n",
    "from magpie.perception import pcd\n",
    "from open3d.web_visualizer import draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from magpie import realsense_wrapper as real\n",
    "rsc = real.RealSense()\n",
    "rsc.initConnection()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-13 15:43:13.136394: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-13 15:43:13.136420: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-13 15:43:13.137360: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-13 15:43:13.142407: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-13 15:43:13.884959: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from magpie.perception.label_owlvit import LabelOWLViT\n",
    "path = \"google/owlvit-base-patch32\"\n",
    "label_vit = LabelOWLViT(pth=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'magpie.gripper' from '/home/will/MAGPIE/magpie/gripper.py'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(gt)\n",
    "importlib.reload(ur5)\n",
    "importlib.reload(magpie.gripper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seg(index):\n",
    "    p, rgbd_image = rsc.getPCD()\n",
    "    image = np.array(rgbd_image.color)\n",
    "    queries = [\"a photo of a red block\"]\n",
    "    # queries = [\"a photo of a tail\"]\n",
    "    # queries = [\"a photo of a black handle of a pair of scissors\"]\n",
    "    abbrevq = [\"bblock\"]\n",
    "    label_vit.set_threshold(0.005)\n",
    "    # bboxes, uboxes = label_vit.label(image, queries, abbrevq, topk=True, plot=True)\n",
    "    bboxes, uboxes = label_vit.label(image, queries, abbrevq, topk=True, plot=False)\n",
    "    rgbd_image, cpcd, tmat, pcaFrame = pcd.get_segment(\n",
    "                                            label_vit.sorted_labeled_boxes_coords, \n",
    "                                            # label_vit.boxes, \n",
    "                                            index, \n",
    "                                            rgbd_image, \n",
    "                                            rsc, \n",
    "                                            type=\"box-dbscan\", \n",
    "                                            #  type=\"box\", \n",
    "                                            #  method=\"quat\", \n",
    "                                            method=\"iterative\", \n",
    "                                            #  display=False,\n",
    "                                            display=True,\n",
    "                                            viz_scale=1000)\n",
    "    tmat, tmat[:3, 3]\n",
    "    offset = (309.63 - 195.0)/1000\n",
    "    tmat[2, 3] += offset\n",
    "    \n",
    "    return cpcd, tmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load arrays in saved_poses/ folder as array of arrays\n",
    "saved_poses = []\n",
    "for i in range(4):\n",
    "    saved_poses.append(np.load(f'saved_poses_2/pose_{i+1}.npy', allow_pickle=True))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ur = ur5.UR5_Interface()\n",
    "# try:\n",
    "#     ur.start()\n",
    "#     np.save('saved_poses_2/pose_4.npy', ur.get_tcp_pose())\n",
    "#     ur.stop()\n",
    "\n",
    "# except Exception as e:\n",
    "#     ur.stop()\n",
    "#     raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ur = ur5.UR5_Interface()\n",
    "# sleepRate = 3\n",
    "\n",
    "# try:\n",
    "#     ur.start()\n",
    "#     currentPose = ur.getPose()\n",
    "#     ur.moveL(saved_poses[1])\n",
    "#     time.sleep(sleepRate)\n",
    "#     ur.open_gripper()\n",
    "#     cpcd, tmat = seg(index=0)\n",
    "    \n",
    "#     tmat_gripper = np.array([[1, 0, 0, 0],\n",
    "#                                  [0, 1, 0, 0],\n",
    "#                                  [0, 0, 1, 0.08],\n",
    "#                                  [0, 0, 0, 1]])\n",
    "\n",
    "#     ee_to_base = ur.get_tcp_pose()\n",
    "\n",
    "#     full_transform = ee_to_base \n",
    "\n",
    "#     o3d.visualization.draw_geometries([cpcd])\n",
    "    \n",
    "#     print(full_transform)\n",
    "#     #ur.moveL(full_transform)\n",
    "\n",
    "#     time.sleep(sleepRate)\n",
    "\n",
    "\n",
    "\n",
    "#     ur.stop()\n",
    "\n",
    "# except Exception as e:\n",
    "#     ur.stop()\n",
    "#     raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ur = ur5.UR5_Interface()\n",
    "# sleepRate = 3\n",
    "\n",
    "# try:\n",
    "#     ur.start()\n",
    "#     currentPose = ur.get_tcp_pose()\n",
    "#     print(currentPose)\n",
    "# except Exception as e:\n",
    "#     ur.stop()\n",
    "#     raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ur = ur5.UR5_Interface()\n",
    "# sleepRate = 3\n",
    "\n",
    "# try:\n",
    "#     ur.start()\n",
    "#     currentPose = ur.getPose()\n",
    "#     p = np.load(f'saved_poses_2/pose_down.npy', allow_pickle=True)\n",
    "#     ur.moveL(p)\n",
    "#     time.sleep(sleepRate)\n",
    "\n",
    "\n",
    "#     ur.stop()\n",
    "\n",
    "# except Exception as e:\n",
    "#     ur.stop()\n",
    "#     raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeeded to open the port\n",
      "Succeeded to change the baudrate\n",
      "Moving speed of dxl ID: 1 set to 100 \n",
      "Moving speed of dxl ID: 2 set to 100 \n",
      "  \u001b[38;5;1m 0.7335  \u001b[0m \u001b[38;5;1m-0.5723  \u001b[0m \u001b[38;5;1m-0.3668  \u001b[0m \u001b[38;5;4m-0.03831 \u001b[0m  \u001b[0m\n",
      "  \u001b[38;5;1m-0.6759  \u001b[0m \u001b[38;5;1m-0.6711  \u001b[0m \u001b[38;5;1m-0.3046  \u001b[0m \u001b[38;5;4m-0.1832  \u001b[0m  \u001b[0m\n",
      "  \u001b[38;5;1m-0.07184 \u001b[0m \u001b[38;5;1m 0.4713  \u001b[0m \u001b[38;5;1m-0.879   \u001b[0m \u001b[38;5;4m 0.6033  \u001b[0m  \u001b[0m\n",
      "  \u001b[38;5;244m 0       \u001b[0m \u001b[38;5;244m 0       \u001b[0m \u001b[38;5;244m 0       \u001b[0m \u001b[38;5;244m 1       \u001b[0m  \u001b[0m\n",
      "\n",
      "Position of dxl ID: 1 set to 303 \n",
      "Position of dxl ID: 2 set to 729 \n",
      "z-axis dot product: [0.979]\n",
      "[Open3D INFO] Window window_0 created.\n",
      "[Open3D INFO] EGL headless mode enabled.\n",
      "[Open3D INFO] ICE servers: [\"stun:stun.l.google.com:19302\", \"turn:user:password@34.69.27.100:3478\", \"turn:user:password@34.69.27.100:3478?transport=tcp\"]\n",
      "WARNING: Using soft CircularBuffer (6144 KiB)\n",
      "FEngine (64 bits) created at 0x7ee16400a080 (threading is enabled)\n",
      "[Open3D INFO] Set WEBRTC_STUN_SERVER environment variable add a customized WebRTC STUN server.\n",
      "[Open3D INFO] WebRTC Jupyter handshake mode enabled.\n",
      "EGL(1.5)\n",
      "OpenGL(4.1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9645909c249433c9159601acbbbbcd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "WebVisualizer(window_uid='window_0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modified indices: [0 0 1]\n",
      "modified indices: [2 0 1]\n",
      "z-axis dot product: [0.769]\n",
      "[Open3D INFO] Window window_1 created.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "457399f6b90c4166abf33b829dd9bab9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "WebVisualizer(window_uid='window_1')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modified indices: [1 0 1]\n",
      "modified indices: [1 0 2]\n",
      "z-axis dot product: [0.424]\n",
      "[Open3D INFO] Window window_2 created.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "568258507e324b568cb2c4537148f118",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "WebVisualizer(window_uid='window_2')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "name = \"pose_5\"\n",
    "sleepRate = 3\n",
    "center = None\n",
    "\n",
    "ur = ur5.UR5_Interface()\n",
    "try:\n",
    "    ur.start()\n",
    "    currentPose = ur.getPose()\n",
    "    print(currentPose)\n",
    "\n",
    "    merged_pcd = o3d.geometry.PointCloud()\n",
    "    ur.open_gripper()\n",
    "    time.sleep(sleepRate)\n",
    "\n",
    "    for k, target_pose in enumerate(saved_poses):\n",
    "\n",
    "        ur.moveL(target_pose)\n",
    "        time.sleep(sleepRate)\n",
    "\n",
    "        # Capture point cloud and transformation matrix\n",
    "        cpcd, tmat = seg(index=0 if k == 0 else 0)\n",
    "\n",
    "        rotation_matrix = np.array([[0, 1, 0, 0],\n",
    "                            [-1, 0, 0, 0],\n",
    "                            [0, 0, 1, 0],\n",
    "                            [0, 0, 0, 1]])\n",
    "\n",
    "        #tmat = tmat @ rotation_matrix\n",
    "\n",
    "\n",
    "        # Transformation matrix for gripper length\n",
    "        tmat_gripper = np.array([[1, 0, 0, -1.15/100],\n",
    "                                 [0, 1, 0, 1.3/100],\n",
    "                                 [0, 0, 1, (309.63 - 195.0)/1000],\n",
    "                                 [0, 0, 0, 1]])\n",
    "\n",
    "        # Get the transformation matrix of the end effector in the base frame\n",
    "        ee_to_base = ur.get_tcp_pose()\n",
    "\n",
    "        cpcd.transform(tmat_gripper)  # Object to end effector frame\n",
    "        cpcd.transform(rotation_matrix)  # End effector to base frame\n",
    "        cpcd.transform(ee_to_base)  # End effector to base frame\n",
    "\n",
    "        # Save the transformed point cloud\n",
    "        o3d.io.write_point_cloud(f\"saved_pcd/cpcd{k+1}_t.ply\", cpcd)\n",
    "\n",
    "        # Use ICP to align the new point cloud with the merged point cloud\n",
    "        if k == 0:\n",
    "            merged_pcd = cpcd\n",
    "        else:\n",
    "            threshold = 0.04  # Distance threshold for ICP\n",
    "            # init_transform = np.eye(4)  # Initial guess for the transformation\n",
    "            # reg_p2p = o3d.pipelines.registration.registration_icp(\n",
    "            #     cpcd, merged_pcd, threshold, init_transform,\n",
    "            #     o3d.pipelines.registration.TransformationEstimationPointToPoint(),\n",
    "            #     o3d.pipelines.registration.ICPConvergenceCriteria(max_iteration=500))\n",
    "            \n",
    "            # # Transform the new point cloud using the result of ICP\n",
    "            # cpcd.transform(reg_p2p.transformation)\n",
    "            \n",
    "            # Merge the point clouds\n",
    "            merged_pcd += cpcd\n",
    "            center = merged_pcd.get_center()\n",
    "            center[2] = center[2] + 233/1000\n",
    "    pose_vector = [center[0], center[1], center[2], 3.14, 0, 0]\n",
    "\n",
    "    final_pos = ur.poseVectorToMatrix(pose_vector)\n",
    "    \n",
    "    ur.moveL(final_pos)\n",
    "    time.sleep(sleepRate)\n",
    "    time.sleep(sleepRate)\n",
    "    ur.close_gripper()\n",
    "\n",
    "    ur.stop()\n",
    "except Exception as e:\n",
    "    ur.stop()\n",
    "    raise e\n",
    "\n",
    "# Save the merged point cloud\n",
    "o3d.io.write_point_cloud(f\"saved_pcd/merged_pcd.ply\", merged_pcd)\n",
    "\n",
    "# Visualize the merged point cloud\n",
    "o3d.visualization.draw_geometries([merged_pcd])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ur = ur5.UR5_Interface()\n",
    "# try:\n",
    "#     ur.start()\n",
    "#     cpcd, tmat = seg(index=0)\n",
    "#     tmat[:3, 3]\n",
    "\n",
    "# except Exception as e:\n",
    "#     ur.stop()\n",
    "#     raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #get center of merged point cloud using open3d get_center\n",
    "# pose_vector = [center[0], center[1], center[2], 3.14, 0, 0]\n",
    "\n",
    "# print(ur.poseVectorToMatrix(pose_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([merged_pcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Capture point cloud and transformation matrix\n",
    "# cpcd, tmat = seg(index=0)\n",
    "# o3d.io.write_point_cloud(f\"saved_pcd/cpcd{1}.ply\", cpcd)\n",
    "\n",
    "# # Transformation matrix for gripper length\n",
    "# tmat_gripper = np.array([[1, 0, 0, 0],\n",
    "#                             [0, 1, 0, 0],\n",
    "#                             [0, 0, 1, 0],\n",
    "#                             [0, 0, 0, 1]])\n",
    "\n",
    "# # Get the transformation matrix of the end effector in the base frame\n",
    "# ee_to_base = ur.get_tcp_pose()\n",
    "\n",
    "\n",
    "# cpcd.transform(ee_to_base)  # End effector to base frame\n",
    "\n",
    "# # Save the transformed point cloud\n",
    "# o3d.io.write_point_cloud(f\"saved_pcd/cpcd{1}_t.ply\", cpcd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged = o3d.io.read_point_cloud(f\"saved_pcd/merged_pcd.ply\")\n",
    "# o3d.visualization.draw_geometries([merged])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # set matrix\n",
    "# # tmat = np.array([[ 0.91574736, -0.35602909,  0.18614527, -0.02848649],\n",
    "# #        [-0.40073104, -0.77640133,  0.48643151,  0.14332736],\n",
    "# #        [ 0.02866033,  0.52004256,  0.85365937,  0.33750796],\n",
    "# #        [ 0.        ,  0.        ,  0.        ,  1.        ]])\n",
    "\n",
    "# tmat = np.array([[ 0.98665647, -0.16180182, -0.01814324,  0.04438557],\n",
    "#        [-0.1565328 , -0.97333117,  0.16770185,  0.04194964],\n",
    "#        [ 0.04479385,  0.1626241 ,  0.98567079,  0.32025074],\n",
    "#        [ 0.        ,  0.        ,  0.        ,  1.        ]])\n",
    "\n",
    "# aperture = 37\n",
    "# # z_offset = G.aperture_to_z(aperture)/1000.0\n",
    "\n",
    "# mmc = copy.deepcopy(tmat[:3, 3])\n",
    "# # grasp_pose = [mmc[1], -mmc[0], mmc[2]]\n",
    "# grasp_pose = mmc\n",
    "# tmat[:3, 3] = [0, 0, 0]\n",
    "# homePose = None\n",
    "# z_offset = 100/1000.0\n",
    "# z_offset -= 0.035\n",
    "# z_offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # move gripper to cartesian pos\n",
    "# # OR orient gripper in place\n",
    "# name = \"pose_5\"\n",
    "# sleepRate = 4\n",
    "# # time.sleep(sleepRate)\n",
    "# ur = ur5.UR5_Interface()\n",
    "# try:\n",
    "#     ur.start()\n",
    "#     currentPose = ur.getPose()\n",
    "#     print(currentPose)\n",
    "\n",
    "#     ur.moveL(saved_poses[4])\n",
    "#     time.sleep(sleepRate)\n",
    "#     time.sleep(sleepRate)\n",
    "#     ur.stop()\n",
    "# except Exception as e:\n",
    "#     ur.stop()\n",
    "#     raise(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index = 1\n",
    "# # this does the [x, y, z] --> [y, -x, z] grasp pose switch, and the -y inversio on the y-axis orientation\n",
    "# # rgbd_image, cpcd, tmat = pcd|.get_segment(label_vit.boxes, index, rgbd_image, rsc, type=\"box\", display=False)\n",
    "# rgbd_image, cpcd, tmat, pcaFrame = pcd.get_segment(\n",
    "#                                         label_vit.sorted_labeled_boxes_coords, \n",
    "#                                         # label_vit.boxes, \n",
    "#                                          index, \n",
    "#                                          rgbd_image, \n",
    "#                                          rsc, \n",
    "#                                          type=\"box-dbscan\", \n",
    "#                                         #  type=\"box\", \n",
    "#                                         #  method=\"quat\", \n",
    "#                                          method=\"iterative\", \n",
    "#                                         #  display=False,\n",
    "#                                          display=True,\n",
    "#                                          viz_scale=1000)\n",
    "# tmat, tmat[:3, 3]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # move gripper to cartesian pos\n",
    "# # OR orient gripper in place\n",
    "# sleepRate = 1.5\n",
    "# # time.sleep(sleepRate)\n",
    "# ur = ur5.UR5_Interface()\n",
    "# try:\n",
    "#     ur.start()\n",
    "#     # homePose = ur.get_tcp_pose()\n",
    "#     homePose = ur.getPose()\n",
    "#     currentPose = ur.getPose()\n",
    "#     desiredPose = np.matmul(np.array(currentPose), tmat)\n",
    "#     print(\"Desired Pose: \", desiredPose)\n",
    "#     # in-place (or best attempt) re-orientation\n",
    "#     # ur.moveL(desiredPose)\n",
    "#     ## move to cartesian pos\n",
    "#     gt.move_to_L(grasp_pose, ur, z_offset=z_offset)    \n",
    "#     print(\"Done moving to block\")\n",
    "#     time.sleep(sleepRate)\n",
    "#     time.sleep(sleepRate)\n",
    "#     ur.stop()\n",
    "# except Exception as e:\n",
    "#     ur.stop()\n",
    "#     raise(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # move home\n",
    "# ur = ur5.UR5_Interface()\n",
    "# try:\n",
    "#     ur.start()\n",
    "#     # time.sleep(sleepRate)\n",
    "#     # homePose = np.array([[-0.024, -0.998, -0.062, -0.261],\n",
    "#     #                     [-0.999,  0.021,  0.035, -0.162],\n",
    "#     #                     [-0.033,  0.063, -0.997,  0.221],\n",
    "#     #                     [ 0.   ,  0.   ,  0.   ,  1.   ]])\n",
    "#     ur.moveL(homePose)\n",
    "#     # gt_home = ur.getPose()\n",
    "#     # print(np.array(gt_home))\n",
    "#     time.sleep(sleepRate * 3)\n",
    "#     ur.stop()\n",
    "# except Exception as e:\n",
    "#     ur.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT EXECUTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # orient and move gripper to cartesian pos\n",
    "# sleepRate = 1.5\n",
    "# ur = ur5.UR5_Interface()\n",
    "# try:\n",
    "#     servoPort = \"/dev/ttyACM0\"\n",
    "#     ur.start()\n",
    "#     time.sleep(sleepRate)\n",
    "#     homePose = ur.get_tcp_pose()    \n",
    "#     '''\n",
    "#     stopping point 2/15:\n",
    "#     this works so far\n",
    "#     take home pos\n",
    "#     add translation on the gripper frame to the goal x, y\n",
    "#     apply tmat to the goal\n",
    "#     move to goal (translates on x, y and orients at the same time)\n",
    "#     ## does this address the fact that orientation is not achievable in standstill?\n",
    "\n",
    "#     then: take orig Z (from original gripper frame): [0, 0, dZ]\n",
    "#     transform by tmat (the current orientation of the gripper)\n",
    "#     add transformed dZ to the goal position\n",
    "#     move\n",
    "#     works!\n",
    "#     '''\n",
    "#     dX,dY,dZ = gt.get_world_frame(grasp_pose, ur, z_offset=z_offset)\n",
    "\n",
    "#     goal1 = copy.deepcopy(homePose)\n",
    "#     goal1 = np.array(goal1)\n",
    "#     # goal1[:3, 3] += [dX, dY, 0]\n",
    "#     goal1[:3, 3] += [dX, dY, dZ]\n",
    "#     goal1 = np.array(goal1) @ tmat\n",
    "#     ur.moveL(goal1)\n",
    "#     time.sleep(sleepRate)\n",
    "\n",
    "#     # todo: take currentPose and validate orientation?\n",
    "#     goal2 = goal1\n",
    "#     posd = [0, 0, dZ] @ tmat[:3, :3]\n",
    "#     goal2 = np.array(goal2)\n",
    "#     goal2[:3, 3] += posd\n",
    "#     # ur.moveL(goal2)\n",
    "#     time.sleep(sleepRate)\n",
    "#     '''\n",
    "#     end of working section\n",
    "#     '''\n",
    "#     ur.stop()\n",
    "# except Exception as e:\n",
    "#     ur.stop()\n",
    "#     raise(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
